/**
 * Import to Database Script
 * Uses existing CSV files from your current importers
 * Simple, professional approach - no code duplication
 */

require('dotenv').config();
const SimpleDatabaseManager = require('../src/database/simple_manager');
const { testConnection } = require('../src/config/database');

async function importToDatabase() {
  console.log('üì• Importing CSV data to PostgreSQL database...\n');
  
  try {
    // Test database connection
    console.log('üîó Testing database connection...');
    const connected = await testConnection();
    if (!connected) {
      throw new Error('Database connection failed');
    }

    // Initialize database manager
    const dbManager = new SimpleDatabaseManager();
    
    // Initialize schema
    console.log('üóÑÔ∏è  Initializing database schema...');
    await dbManager.initializeSchema();
    
    // Import all CSV files
    console.log('üìä Starting CSV import process...\n');
    const result = await dbManager.importAllCSVFiles();
    
    // Show final statistics
    console.log('\nüìà Database Statistics:');
    const stats = await dbManager.getStats();
    
    if (stats.tradfi.length > 0) {
      console.log('\nüè¶ TradFi Assets:');
      stats.tradfi.forEach(asset => {
        const days = Math.ceil((asset.last_timestamp - asset.first_timestamp) / (1000 * 60 * 60 * 24));
        console.log(`   üìä ${asset.symbol}: ${parseInt(asset.record_count).toLocaleString()} records (${days} days)`);
        console.log(`      üìÖ ${asset.first_timestamp.toISOString().split('T')[0]} ‚Üí ${asset.last_timestamp.toISOString().split('T')[0]}`);
      });
    }
    
    if (stats.crypto.length > 0) {
      console.log('\nü™ô Crypto Assets:');
      stats.crypto.forEach(asset => {
        const days = Math.ceil((asset.last_timestamp - asset.first_timestamp) / (1000 * 60 * 60 * 24));
        console.log(`   üìä ${asset.symbol} (${asset.exchange}): ${parseInt(asset.record_count).toLocaleString()} records (${days} days)`);
        console.log(`      üìÖ ${asset.first_timestamp.toISOString().split('T')[0]} ‚Üí ${asset.last_timestamp.toISOString().split('T')[0]}`);
      });
    }
    
    console.log('\nüìÅ Metadata files generated:');
    console.log('   üìÑ ./metadata/tradfi/ - TradFi asset metadata');
    console.log('   üìÑ ./metadata/crypto/ - Crypto asset metadata'); 
    console.log('   üìã ./metadata/summary.json - Overall summary');
    
    console.log('\n‚úÖ Database import completed successfully!');
    console.log('\nüí° Next steps:');
    console.log('   - Run more ETL cycles with different date ranges');
    console.log('   - Check metadata files for data coverage');
    console.log('   - Set up periodic updates');
    
    process.exit(0);
    
  } catch (error) {
    console.error('\n‚ùå Database import failed:', error.message);
    console.error('\nüí° Make sure:');
    console.error('   - Database connection is working');
    console.error('   - CSV files exist in ./data/tradfi/ and ./data/crypto/');
    console.error('   - Run ETL pipeline first: npm run import:all');
    process.exit(1);
  }
}

// Handle graceful shutdown
process.on('SIGINT', () => {
  console.log('\n\n‚ö†Ô∏è  Import interrupted');
  process.exit(1);
});

if (require.main === module) {
  importToDatabase();
}

module.exports = importToDatabase;